{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start...\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "import copy\n",
    "from Bio import SeqIO\n",
    "import argparse\n",
    "from utils.bert import get_config, BertModel, set_learned_params, BertForMaskedLM, visualize_attention, show_base_PCA, fix_params\n",
    "from module import Train_Module\n",
    "from dataload import DATA, MyDataset \n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score, completeness_score, homogeneity_score\n",
    "import torch.nn.functional as F\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans, AgglomerativeClustering, SpectralClustering \n",
    "import itertools  \n",
    "from dataload import *\n",
    "from MLM_SFP import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_device(model):\n",
    "    print(\"device: \", 'cuda')\n",
    "    print('-----start-------')\n",
    "    model.to('cuda')\n",
    "\n",
    "    model = torch.nn.DataParallel(model) # make parallel\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n",
      "-----start-------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = get_config(file_path = \"./RNA_bert_config.json\")\n",
    "\n",
    "config.hidden_size = config.num_attention_heads * config.multiple    \n",
    "\n",
    "model = BertModel(config)\n",
    "model = BertForMaskedLM(config, model)\n",
    "model = model_device(model = model)\n",
    "\n",
    "model.load_state_dict(torch.load('bert_mul_2.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): BertForMaskedLM(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(6, 120, padding_idx=0)\n",
       "        (position_embeddings): Embedding(440, 120)\n",
       "        (token_type_embeddings): Embedding(2, 120)\n",
       "        (LayerNorm): BertLayerNorm()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-5): 6 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (selfattn): BertSelfAttention(\n",
       "                (query): Linear(in_features=120, out_features=120, bias=True)\n",
       "                (key): Linear(in_features=120, out_features=120, bias=True)\n",
       "                (value): Linear(in_features=120, out_features=120, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=120, out_features=120, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=120, out_features=40, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=40, out_features=120, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=120, out_features=120, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (cls): BertPreTrainingHeads(\n",
       "      (predictions): MaskedWordPredictions(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=120, out_features=120, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "        )\n",
       "        (decoder): Linear(in_features=120, out_features=6, bias=False)\n",
       "      )\n",
       "      (predictions_ss): MaskedWordPredictions(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=120, out_features=120, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "        )\n",
       "        (decoder): Linear(in_features=120, out_features=8, bias=False)\n",
       "      )\n",
       "      (seq_relationship): Linear(in_features=120, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = config.max_position_embeddings\n",
    "def load_data_EMB(record):\n",
    "    gapped_seqs = []\n",
    "    seqs = []\n",
    "\n",
    "    gapped_seq = str(record).upper()\n",
    "    gapped_seq = gapped_seq.replace(\"T\", \"U\")\n",
    "    seq = gapped_seq.replace('-', '')\n",
    "    if set(seq) <= set(['A', 'T', 'G', 'C', 'U']) and len(list(seq)) < max_length:\n",
    "        seqs.append(seq)\n",
    "        gapped_seqs.append(gapped_seq)\n",
    "    gapped_seqs = np.tile(onehot_seq(gapped_seqs, max_length*5), (1, 1))\n",
    "    family = np.tile(np.array([1]), 1)\n",
    "    seqs_len = np.tile(np.array([len(i) for i in seqs]), 1)   \n",
    "    k = 1   \n",
    "    kmer_seqs = kmer(seqs, k)\n",
    "    masked_seq, low_seq = mask(kmer_seqs, rate = 0, mag = 1)\n",
    "    kmer_dict = make_dict(k)\n",
    "    swap_kmer_dict = {v: k for k, v in kmer_dict.items()}\n",
    "    masked_seq = np.array(convert(masked_seq, kmer_dict, max_length))\n",
    "    low_seq = np.array(convert(low_seq, kmer_dict, max_length))\n",
    "\n",
    "    return seqs, low_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.IntTensor(load_data_EMB('AAA')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = model(tokens)[2].squeeze(0)[:3]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python MLM_SFP.py --pretraining bert_mul_2.pth --data_embedding sample/aln/sample.raw.fa --embedding_output ./test.txt --batch 40"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
